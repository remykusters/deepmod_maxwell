{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Burgers, tests 1D input\n",
    "\n",
    "# General imports\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# DeepMoD stuff\n",
    "from deepymod_torch.DeepMod import DeepMod\n",
    "from deepymod_torch.library_functions import library_1D_in\n",
    "from deepymod_torch.training import train_deepmod, train_mse\n",
    "\n",
    "# Setting cuda\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "# Settings for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "data = np.load('data/burgers.npy', allow_pickle=True).item()\n",
    "X = np.transpose((data['t'].flatten(), data['x'].flatten()))\n",
    "y = np.real(data['u']).reshape((data['u'].size, 1))\n",
    "number_of_samples = 1000\n",
    "\n",
    "idx = np.random.permutation(y.size)\n",
    "X_train = torch.tensor(X[idx, :][:number_of_samples], dtype=torch.float32, requires_grad=True)\n",
    "y_train = torch.tensor(y[idx, :][:number_of_samples], dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running DeepMoD\n",
    "config = {'input_dim': 2, 'hidden_dims': [20, 20, 20, 20, 20, 20], 'output_dim': 1, 'library_function': library_1D_in, 'library_args':{'poly_order': 2, 'diff_order': 2}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepMod(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([{'params': model.network.parameters(), 'lr':0.002}, {'params': model.fit.parameters(), 'lr':0.002}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, target, optimizer, max_iterations, loss_func_args):\n",
    "    '''Trains the deepmod model with MSE, regression and l1 cost function. Updates model in-place.'''\n",
    "    start_time = 0#time.time()\n",
    "    number_of_terms = [9]#[coeff_vec.shape[0] for coeff_vec in model(data)[3]]\n",
    "    #board = Tensorboard(number_of_terms)\n",
    "\n",
    "    # Training\n",
    "    print('| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       L1 |')\n",
    "    for iteration in torch.arange(0, max_iterations + 1):\n",
    "        # Calculating prediction and library and scaling\n",
    "        prediction, time_deriv_list, sparse_theta_list, coeff_vector_list = model(data)\n",
    "        coeff_vector_scaled_list = scaling(coeff_vector_list, sparse_theta_list, time_deriv_list) \n",
    "        \n",
    "        # Calculating loss\n",
    "        loss_reg = reg_loss(time_deriv_list, sparse_theta_list, coeff_vector_list)\n",
    "        loss_mse = mse_loss(prediction, target)\n",
    "        loss_l1 = l1_loss(coeff_vector_scaled_list, loss_func_args['l1'])\n",
    "        loss = torch.sum(loss_reg) + torch.sum(loss_mse) + torch.sum(loss_l1)\n",
    "        \n",
    "        # Writing\n",
    "        if iteration % 100 == 0:\n",
    "            progress(iteration, start_time, max_iterations, loss.item(), torch.sum(loss_mse).item(), torch.sum(loss_reg).item(), torch.sum(loss_l1).item())\n",
    "            #board.write(iteration, loss, loss_mse, loss_reg, loss_l1, coeff_vector_list, coeff_vector_scaled_list)\n",
    "\n",
    "        # Optimizer step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    #board.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, X_train, y_train, optimizer, 1000, {'l1':1e-5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}